{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d48890d7",
   "metadata": {},
   "source": [
    "#### 1. What are the key tasks that machine learning entails? What does data pre-processing imply?\n",
    "\n",
    "\n",
    "Ans:\n",
    "``Machine learning involves tasks such as data collection, feature engineering, model selection, training, and evaluation. Data pre-processing is a crucial step where raw data is cleaned, transformed, and organized to enhance its quality and suitability for machine learning algorithms, ensuring accurate and effective model training and performance.``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415c1d02",
   "metadata": {},
   "source": [
    "#### 2. Describe quantitative and qualitative data in depth. Make a distinction between the two.\n",
    "Ans:\n",
    "Quantitative data involves numerical values and measurable attributes, enabling statistical analysis and objective comparisons. Qualitative data, on the other hand, comprises non-numeric information, often describing qualities, behaviors, or characteristics. While quantitative data is quantitative and objective, qualitative data is qualitative and subjective, providing richer contextual insights.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b342319b",
   "metadata": {},
   "source": [
    "#### 3. Create a basic data collection that includes some sample records. Have at least one attribute from each of the machine learning data types.\n",
    "\n",
    "**Ans:** The following is a basic data collection that includes some sample records.\n",
    "\n",
    "1. **Determine What Information You Want to Collect:** The first thing you need to do is choose what details you want to collect. You’ll need to decide what topics the information will cover, who you want to collect it from and how much data you need. Your goals — what you hope to accomplish using your data — will determine your answers to these questions. As an example, you may decide to collect data about which type of articles are most popular on your website among visitors who are between the ages of 18 and 34. You might also choose to gather information about the average age of all of the customers who bought a product from your company within the last month.\n",
    "\n",
    "2. **Set a Timeframe for Data Collection:** Next, you can start formulating your plan for how you’ll collect your data. In the early stages of your planning process, you should establish a timeframe for your data collection. You may want to gather some types of data continuously. When it comes to transactional data and website visitor data, for example, you may want to set up a method for tracking that data over the long term. If you’re tracking data for a specific  campaign, however, you’ll track it over a defined period. In these instances, you’ll have a schedule for when you’ll start and end your data collection.\n",
    "\n",
    "3. **Determine Your Data Collection Method:** At this step, you will choose the data collection method that will make up  the core of your data-gathering strategy. To select the right collection method, you’ll need to consider the type of  information you want to collect, the timeframe over which you’ll obtain it and the other aspects you determined. \n",
    "\n",
    "4. **Collect the Data:** Once you have finalized your plan, you can implement your data collection strategy and start collecting data. You can store and organize your data in your DMP. Be sure to stick to your plan and check on its progress regularly. It may be useful to create a schedule for when you will check in with how your data collection is proceeding, especially if you are collecting data continuously. You may want to make updates to your plan as conditions change and you get new information.\n",
    "\n",
    "5. **Analyze the Data and Implement Your Findings:** Once you’ve collected all of your data, it’s time to analyze it and organize your findings. The analysis phase is crucial because it turns raw data into valuable insights that you can use to enhance your marketing strategies, products and business decisions. You can use the analytics tools built into our DMP to help with this step. Once you’ve uncovered the patterns and insights in your data, you can implement the findings to improve your business."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39754767",
   "metadata": {},
   "source": [
    "#### 4. What are the various causes of machine learning data issues? What are the ramifications ?\n",
    "\n",
    "**Ans:** Noisy data, dirty data, and incomplete data are the quintessential enemies of ideal Machine Learning. The solution to this conundrum is to take the time to evaluate and scope data with meticulous data governance, data integration, and  data exploration until you get clear data. Ramifications or major issues in machine learning are:\n",
    "1. Five practical issues in machine learning and the business implications Data quality.\n",
    "2. Machine learning systems rely on data.\n",
    "3. The complexity and quality trade-off.\n",
    "4. Sampling bias in data.\n",
    "5. Changing expectations and concept drift.\n",
    "6. Monitoring and maintenance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f41d2ce",
   "metadata": {},
   "source": [
    "#### 5. Demonstrate various approaches to categorical data exploration with appropriate examples ?\n",
    "\n",
    "**Ans:** Various approaches to categorical data exploration are:\n",
    "1. **Unique value count:** One of the first things which can be useful during data exploration is to see how many unique values\n",
    "are there in categorical columns.\n",
    "2. **Frequency Count:** Frequency count is finding how frequent individual values occur in column.\n",
    "3. **Variance:** Variance gives a good indication how the values are spread.\n",
    "4. **Pareto Analysis:** Pareto analysis is a creative way of focusing on what is important. Pareto 80–20 rule can be effectively used in data exploration.\n",
    "5. **Histogram:** Histogram are one of the data scientists favourite data exploration techniques. It gives information on the range of values in which most of the values fall. It also gives information on whether there is any skew in data.\n",
    "6. **Correlation Heat-map between all numeric columns:** The term correlation refers to a mutual relationship or association between two things.\n",
    "7. **Pearson Correlation and Trend between two numeric columns:** Once you have visualised correlation heat-map , the next step is to see the correlation trend between two specific numeric columns.\n",
    "8. **Outlier overview:** Finding something unusual in data is called Outlier detection (also known as anomaly detection). These outliers represent something unusual, rare , anomaly or something exceptional. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95aac876",
   "metadata": {},
   "source": [
    "#### 6. How would the learning activity be affected if certain variables have missing values? Having said that, what can be done about it?\n",
    "\n",
    "**Ans:** Even in a Well-Designed & Controlled study, Missing data occurs in almost all research. Missing data can reduce the statistical power of a study and can produce biased estimates, leading to invalid conclusions. \n",
    "\n",
    "- Real-world data collection has its own set of problems, It is often very messy which includes missing data, presence of outliers, unstructured manner, etc. \n",
    "- Before looking for any insights from the data, we have to first perform  preprocessing tasks which then only allow us to use that data for further observation and train our machine learning model. \n",
    "- Missing value in a dataset is a very common phenomenon in the reality. \n",
    "- Missing value correction is required to reduce bias and to produce powerful suitable models.\n",
    "- Most of the algorithms can’t handle missing data, thus you need to act in some way to simply not let your code crash. So, let’s begin with the methods to solve the problem.\n",
    "- Methods for dealing with missing values. The popular methods which are used by the machine learning community to handle the missing value for categorical variables in the dataset are as follows: Delete the observations: If there is a large number of observations in the dataset, where all the classes to be predicted are sufficiently represented in the training data, then try deleting the missing value observations, which would not bring significant change in your feed to your model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57cfc43",
   "metadata": {},
   "source": [
    "#### 7. Describe the various methods for dealing with missing data values in depth ?\n",
    "**Ans:**\n",
    "1. ``Deletion``: Eliminate rows or columns with missing values, sacrificing data.\n",
    "2. ``Imputation``: Substitute missing values with estimated ones based on statistical measures or algorithms.\n",
    "3. ``Mean/Median/Mode Imputation``: Fill missing values with the mean, median, or mode of the observed data.\n",
    "4. ``Regression Imputation``: Predict missing values using regression models.\n",
    "5. ``Multiple Imputation``: Generate multiple imputed datasets for robust analysis.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6292bdf2",
   "metadata": {},
   "source": [
    "#### 8. What are the various data pre-processing techniques? Explain dimensionality reduction and function selection in a few words ?\n",
    "\n",
    "\n",
    "**Ans:** Data Pre-processing Techniques:\n",
    "\n",
    "1. ``Cleaning``: Handling missing values and correcting errors.\n",
    "2. ``Normalization/Scaling``: Standardizing features for consistent scales.\n",
    "3. ``Transformation``: Log or power transformations for non-linear relationships.\n",
    "4. ``Encoding``: Converting categorical variables into numerical formats.\n",
    "5. ``Feature Engineering``: Creating new features to enhance model performance.\n",
    "6. ``Dimensionality Reduction``:\n",
    "It involves reducing the number of input variables in a dataset while preserving key information. Techniques like PCA (Principal Component Analysis) or t-SNE (t-distributed Stochastic Neighbor Embedding) help in capturing essential patterns while reducing computational complexity.\n",
    "\n",
    "7. ``Feature Selection``:\n",
    "It aims to choose the most relevant features for modeling. Methods include filter methods (statistical tests), wrapper methods (using model performance), and embedded methods (feature importance from models). Feature selection enhances model efficiency and interpretability.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27efc409",
   "metadata": {},
   "source": [
    "##### 9.Make brief notes on of the following ?\n",
    "1. What is the IQR? What criteria are used to assess it?\n",
    "2. Describe the various components of a box plot in detail? When will the lower whisker    surpass the upper whisker in length? How can box plots be used to identify outliers?\n",
    "\n",
    "\n",
    "**Ans:** The following is the brief notes on the following topics:\n",
    "\n",
    "- **What is the IQR? What criteria are used to assess it?**\n",
    "    - Q1 is the first quartile of the data, i.e., to say 25% of the data lies between minimum and Q1. \n",
    "    - Q3 is the third quartile of the data, i.e., to say 75% of the data lies between minimum and Q3. \n",
    "    - The difference between Q3 and Q1 is called the Inter-Quartile Range or IQR.\n",
    "\n",
    "\n",
    "- **Describe the various components of a box plot in detail? When will the lower whisker surpass  the upper whisker in length? How can box plots be used to identify outliers?**\n",
    "    - minimum is the minimum value in the dataset\n",
    "    - maximum is the maximum value in the dataset.\n",
    "    - So the difference between the two tells us about the range of dataset.\n",
    "    - The median is the median (or centre point), also called second quartile, of the data (resulting from the fact that the data is ordered).\n",
    "    - Q1 is the first quartile of the data, i.e., to say 25% of the data lies between minimum and Q1.\n",
    "    - Q3 is the third quartile of the data, i.e., to say 75% \n",
    "    - When the data is left skewed, lower whisker will be longer than upper whisker. \n",
    "    - To detect the outliers this method is used, we define a new range, let’s call it decision range, and any  data point lying outside this range is considered as outlier and is accordingly dealt with. The range is  as given below:\n",
    "    `Lower Bound: (Q1 - 1.5 * IQR)Upper Bound: (Q3 + 1.5 * IQR)`\n",
    "    - The difference between Q3 and Q1 is called the Inter-Quartile Range or IQR. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dcf8d8",
   "metadata": {},
   "source": [
    "#### 10. Make brief notes on any two of the following ?\n",
    "1. Data collected at regular intervals\n",
    "2. The gap between the quartiles\n",
    "3. Use a cross-tab\n",
    "\n",
    "\n",
    "**Ans:** The following are the breif notes about:\n",
    "- **Data collected at regular intervals:**\n",
    "    - Interval data is one of the two types of discrete data. \n",
    "    - An example of interval data is the data collected on a  thermometer—its gradation or markings are equidistant. \n",
    "    - Unlike ordinal data, interval data always take numerical values where the distance between two points on the scale is standardised and equal.\n",
    "    \n",
    "    \n",
    "- **The gap between the quartiles:** \n",
    "    - Q1 is the first quartile of the data, i.e., to say 25% of the data lies between minimum and Q1. \n",
    "    - Q3 is the third quartile of the data, i.e., to say 75% of the data lies between minimum and Q3. \n",
    "    - The difference between Q3 and Q1 is called the Inter-Quartile Range or IQR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc0ee32",
   "metadata": {},
   "source": [
    "#### 11. Make a comparison between ?\n",
    "1. Data with nominal and ordinal values\n",
    "2. Histogram and box plot\n",
    "3. The average and median\n",
    "\n",
    "\n",
    "**Ans:**\n",
    "- **Data with Nominal and Ordinal Values:** \n",
    "   - Nominal: Represents categories with no inherent order (e.g., colors, gender).\n",
    "   - Ordinal: Categories with a meaningful order but no fixed interval (e.g., education levels, survey ratings).\n",
    "   - Comparison: Nominal data lacks a specific order, while ordinal data exhibits a meaningful hierarchy.\n",
    "   \n",
    "\n",
    "- **Histogram and Box Plot:**\n",
    "    - Histogram: Displays the distribution of continuous data through bars. Provides insights into frequency and shape.\n",
    "    - Box Plot (Box-and-Whisker Plot): Illustrates the summary statistics of a dataset, including median, quartiles, and outliers.\n",
    "    - Comparison: Histograms emphasize data distribution, while box plots highlight central tendency and variability.\n",
    "\n",
    "- **Average and Median:**\n",
    "\n",
    "    - Average (Mean): Calculated by summing values and dividing by the count. Sensitive to outliers.\n",
    "    - Median: Middle value when data is ordered. Robust to outliers.\n",
    "    - Comparison: Median is robust to extreme values, providing a better measure of central tendency in skewed distributions, while the mean can be influenced by outliers.\n",
    "   \n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6017211",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
